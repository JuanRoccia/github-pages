import { j as createVNode, F as Fragment, s as spreadAttributes } from './astro.d584cb1b.mjs';
import '@astrojs/internal-helpers/path';
import 'html-escaper';

const images = {
					
				};

				function updateImageReferences(html) {
					return html.replaceAll(
						/__ASTRO_IMAGE_="([^"]+)"/gm,
						(full, imagePath) => spreadAttributes({src: images[imagePath].src, ...images[imagePath].attributes})
					);
				}

				const html = updateImageReferences("<h3 id=\"tecnologías-y-herramientas\">Tecnologías y Herramientas:</h3>\n<p>Hugging Face, Orca Mini Nomic, GPT4ALL, Flask, Tailwind CSS, SpeechRecognition, Web Speech API, HTML, CSS, JavaScript, Python.</p>\n<h1 id=\"audiogpt\">AudioGPT</h1>\n<p>AudioGPT es una innovadora aplicación web que permite a los usuarios interactuar con un chatbot conversacional utilizando solo su voz. Durante el desarrollo de este proyecto, exploré y probé varios modelos de Hugging Face antes de decidirme por GPT4ALL, específicamente el modelo Orca Mini de Nomic, debido a su eficiencia y precisión en la generación de texto.</p>\n<h3 id=\"ruta-de-desarrollo\">Ruta de Desarrollo</h3>\n<p>La aplicación fue desarrollada utilizando Flask, un microframework de Python, que me permitió integrar y comunicar el modelo de IA con la interfaz de usuario. Para capturar la voz del usuario, implementé una funcionalidad que utiliza las capacidades de grabación de voz del navegador. Una vez que el usuario proporciona su entrada de voz, esta se transcribe a texto, proceso que se realiza con una librería que convierte el audio en texto legible. Posteriormente, este texto se envía al modelo de IA para generar una respuesta adecuada.</p>\n<h3 id=\"respuesta-del-modelo\">Respuesta del Modelo</h3>\n<p>Una vez que el modelo proporciona la respuesta, esta se convierte nuevamente en audio para que el usuario pueda escucharla. Además, la respuesta también se muestra en un chat en la interfaz de usuario, ofreciendo así dos modalidades de interacción: auditiva y visual.</p>\n<h3 id=\"diseño-uiux\">Diseño UI/UX</h3>\n<p>En cuanto al diseño y estética de la aplicación, utilicé Tailwind CSS, un marco de diseño de utilidad de vanguardia, para crear una interfaz amigable y moderna. Esta elección no solo mejoró la apariencia de la aplicación, sino que también optimizó la experiencia del usuario, haciendo que la interacción con el chatbot fuera fluida y agradable.</p>\n<h3 id=\"conclusión\">Conclusión</h3>\n<p>En resumen, AudioGPT es el resultado de una cuidadosa selección de tecnologías y herramientas, todas elegidas con el objetivo de proporcionar una experiencia de chatbot por voz única y efectiva.</p>\n<h2 id=\"estructura-del-proyecto\">Estructura del Proyecto</h2>\n<p>El proyecto tiene la siguiente estructura de archivos:</p>\n<pre is:raw=\"\" class=\"astro-code github-dark\" style=\"background-color: #24292e; overflow-x: auto;\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #e1e4e8\">.</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">├── modelos</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   └── orca-mini-3b.ggmlv3.q4_0.bin</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">├── static</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   ├── img</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   │   ├── (archivos de imágenes)</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   │   └── favicon</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   │       └── (archivos de favicon)</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   └── script.js</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">├── templates</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">│   └── index.html</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">├── main.py</span></span>\n<span class=\"line\"><span style=\"color: #e1e4e8\">└── README.md</span></span></code></pre>\n<h3 id=\"cómo-funciona\">Cómo Funciona</h3>\n<p>La aplicación utiliza la síntesis de voz y el reconocimiento de voz del navegador para interactuar con el usuario. Cuando el usuario habla, su voz se transcribe a texto y se envía a un modelo de IA en el servidor. El modelo de IA genera una respuesta, que luego se convierte en voz y se reproduce para el usuario.</p>\n<h3 id=\"código\">Código</h3>\n<p>El proyecto es una aplicación Flask. El archivo <code>main.py</code> contiene el servidor Flask y la lógica de la aplicación. El archivo <code>script.js</code> contiene el código JavaScript para la interacción del usuario en el front-end. El archivo <code>index.html</code> es la plantilla HTML para la interfaz de usuario.</p>\n<h3 id=\"uso\">Uso</h3>\n<p>Para usar la aplicación, los usuarios simplemente necesitan visitar la URL de la aplicación en su navegador. Actualmente solo pueden interactuar con el chatbot utilizando el reconocimiento de voz.</p>\n<h2 id=\"despliegue\">Despliegue</h2>\n<p>Para finalizar el desarrollo y deploy de la aplicación use Replit y esta disponible en la siguiente URL del Deployment:</p>\n<p><a href=\"https://audio-gpt-juanroccia.replit.app/\">https://audio-gpt-juanroccia.replit.app/</a></p>\n<p>Y en el caso de quedarse sin fondos también esta disponible la URL del Webview:</p>\n<p><a href=\"https://audiogpt.juanroccia.repl.co/\">https://audiogpt.juanroccia.repl.co/</a></p>\n<h3 id=\"estado-actual-y-futuro-del-proyecto\">Estado Actual y Futuro del Proyecto</h3>\n<p>Aunque el proyecto ha avanzado mucho y ahora utiliza un modelo de IA más grande, todavía se encuentra en una etapa inicial. Puede haber fallas, demoras, etc. Sin embargo, el proyecto está en continuo desarrollo y habrá nuevas versiones con mejoras e implementaciones en el futuro.</p>");

				const frontmatter = {"title":"AudioGPT","publishDate":"2020-03-04T00:00:00.000Z","img":"/assets/stock-3.jpg","img_alt":"Pearls of silky soft white cotton, bubble up under vibrant lighting","description":"Aplicación de Inteligencia Artificial del tipo Chatbot Conversacional.\n","tags":["Chatbot","AI","Text Generation"]};
				const file = "C:/Users/juanm/Desarrollo Web/GitHubPages-BranchWeb-LinkTree/juanroccia.github.io/src/content/work/nested/duvet-genius.md";
				const url = undefined;
				function rawContent() {
					return "\n### Tecnologías y Herramientas:\n\nHugging Face, Orca Mini Nomic, GPT4ALL, Flask, Tailwind CSS, SpeechRecognition, Web Speech API, HTML, CSS, JavaScript, Python.\n\n# AudioGPT\n\nAudioGPT es una innovadora aplicación web que permite a los usuarios interactuar con un chatbot conversacional utilizando solo su voz. Durante el desarrollo de este proyecto, exploré y probé varios modelos de Hugging Face antes de decidirme por GPT4ALL, específicamente el modelo Orca Mini de Nomic, debido a su eficiencia y precisión en la generación de texto.\n\n### Ruta de Desarrollo\n\nLa aplicación fue desarrollada utilizando Flask, un microframework de Python, que me permitió integrar y comunicar el modelo de IA con la interfaz de usuario. Para capturar la voz del usuario, implementé una funcionalidad que utiliza las capacidades de grabación de voz del navegador. Una vez que el usuario proporciona su entrada de voz, esta se transcribe a texto, proceso que se realiza con una librería que convierte el audio en texto legible. Posteriormente, este texto se envía al modelo de IA para generar una respuesta adecuada.\n\n### Respuesta del Modelo\n\nUna vez que el modelo proporciona la respuesta, esta se convierte nuevamente en audio para que el usuario pueda escucharla. Además, la respuesta también se muestra en un chat en la interfaz de usuario, ofreciendo así dos modalidades de interacción: auditiva y visual.\n\n### Diseño UI/UX\n\nEn cuanto al diseño y estética de la aplicación, utilicé Tailwind CSS, un marco de diseño de utilidad de vanguardia, para crear una interfaz amigable y moderna. Esta elección no solo mejoró la apariencia de la aplicación, sino que también optimizó la experiencia del usuario, haciendo que la interacción con el chatbot fuera fluida y agradable.\n\n### Conclusión\n\nEn resumen, AudioGPT es el resultado de una cuidadosa selección de tecnologías y herramientas, todas elegidas con el objetivo de proporcionar una experiencia de chatbot por voz única y efectiva.\n\n\n## Estructura del Proyecto\n\nEl proyecto tiene la siguiente estructura de archivos:\n\n```\n.\n├── modelos\n│   └── orca-mini-3b.ggmlv3.q4_0.bin\n├── static\n│   ├── img\n│   │   ├── (archivos de imágenes)\n│   │   └── favicon\n│   │       └── (archivos de favicon)\n│   └── script.js\n├── templates\n│   └── index.html\n├── main.py\n└── README.md\n```\n\n### Cómo Funciona\n\nLa aplicación utiliza la síntesis de voz y el reconocimiento de voz del navegador para interactuar con el usuario. Cuando el usuario habla, su voz se transcribe a texto y se envía a un modelo de IA en el servidor. El modelo de IA genera una respuesta, que luego se convierte en voz y se reproduce para el usuario.\n\n### Código\n\nEl proyecto es una aplicación Flask. El archivo `main.py` contiene el servidor Flask y la lógica de la aplicación. El archivo `script.js` contiene el código JavaScript para la interacción del usuario en el front-end. El archivo `index.html` es la plantilla HTML para la interfaz de usuario.\n\n### Uso\n\nPara usar la aplicación, los usuarios simplemente necesitan visitar la URL de la aplicación en su navegador. Actualmente solo pueden interactuar con el chatbot utilizando el reconocimiento de voz.\n\n## Despliegue\n\nPara finalizar el desarrollo y deploy de la aplicación use Replit y esta disponible en la siguiente URL del Deployment: \n\nhttps://audio-gpt-juanroccia.replit.app/ \n\nY en el caso de quedarse sin fondos también esta disponible la URL del Webview: \n\nhttps://audiogpt.juanroccia.repl.co/\n\n### Estado Actual y Futuro del Proyecto\n\nAunque el proyecto ha avanzado mucho y ahora utiliza un modelo de IA más grande, todavía se encuentra en una etapa inicial. Puede haber fallas, demoras, etc. Sin embargo, el proyecto está en continuo desarrollo y habrá nuevas versiones con mejoras e implementaciones en el futuro.";
				}
				function compiledContent() {
					return html;
				}
				function getHeadings() {
					return [{"depth":3,"slug":"tecnologías-y-herramientas","text":"Tecnologías y Herramientas:"},{"depth":1,"slug":"audiogpt","text":"AudioGPT"},{"depth":3,"slug":"ruta-de-desarrollo","text":"Ruta de Desarrollo"},{"depth":3,"slug":"respuesta-del-modelo","text":"Respuesta del Modelo"},{"depth":3,"slug":"diseño-uiux","text":"Diseño UI/UX"},{"depth":3,"slug":"conclusión","text":"Conclusión"},{"depth":2,"slug":"estructura-del-proyecto","text":"Estructura del Proyecto"},{"depth":3,"slug":"cómo-funciona","text":"Cómo Funciona"},{"depth":3,"slug":"código","text":"Código"},{"depth":3,"slug":"uso","text":"Uso"},{"depth":2,"slug":"despliegue","text":"Despliegue"},{"depth":3,"slug":"estado-actual-y-futuro-del-proyecto","text":"Estado Actual y Futuro del Proyecto"}];
				}
				async function Content() {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;
					const contentFragment = createVNode(Fragment, { 'set:html': html });
					return contentFragment;
				}
				Content[Symbol.for('astro.needsHeadRendering')] = true;

export { Content, compiledContent, Content as default, file, frontmatter, getHeadings, images, rawContent, url };
